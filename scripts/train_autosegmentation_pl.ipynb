{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skull Segmentation\n",
    "\n",
    "Training a segmentation model with Pytorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from monai.transforms import (\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    ")\n",
    "from monai.data import CacheDataset, DataLoader\n",
    "from autoimplantpipe import UNetSegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_data_dict(data_dir: str):\n",
    "    \"\"\"\n",
    "    Use for create data dict from data dir.\n",
    "    \"\"\"\n",
    "    images = glob(f\"{data_dir}/*/*_resampled.nii\")\n",
    "    labels = glob(f\"{data_dir}/*/*_label.nii\")\n",
    "    data_dicts = [\n",
    "        {\"image\": image_name, \"label\": label_name}\n",
    "        for image_name, label_name in zip(images, labels)\n",
    "    ]\n",
    "    return data_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data dir and create training and validation data dict\n",
    "train_files = set_data_dict(\"Datasets_skull/train\")\n",
    "val_files = set_data_dict(\"Datasets_skull/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup transform for training and validation data\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-43,\n",
    "            a_max=453,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(0.5, 0.5, 0.625),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(96, 96, 96),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-43,\n",
    "            a_max=453,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(0.5, 0.5, 0.625),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataloader for training and validation\n",
    "train_ds = CacheDataset(\n",
    "    data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=4\n",
    ")\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=4)\n",
    "\n",
    "val_ds = CacheDataset(\n",
    "    data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=4\n",
    ")\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train segmentation with Pytorch lightning Unet model\n",
    "wandb_logger = WandbLogger(project=\"<project_name>\", log_model=\"all\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_dice\",\n",
    "    mode=\"max\",\n",
    "    dirpath=\"checkpoints/\",\n",
    "    filename=\"sample-mnist-{epoch:02d}-{val_dice:.2f}\",\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=5,\n",
    "    logger=wandb_logger,\n",
    "    log_every_n_steps=1,\n",
    "    callbacks=checkpoint_callback,\n",
    "    default_root_dir=\"model/\",\n",
    ")\n",
    "model = UNetSegmentation()\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meticuly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
